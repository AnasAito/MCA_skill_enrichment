{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import en_core_web_sm\n",
    "from escopy.text_cleaning_utils import clean_text\n",
    "from escopy.extract_skills import detect_skills\n",
    "import pandas as pd \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'surface_form_matcher_v02_1.pickle'\n",
    "model = pickle.load(open(path, \"rb\"))\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# main \n",
    "\n",
    "job_description = \"\"\"\n",
    "Advanced skills in SQL, Python, or similar technologies\n",
    "Experience with Time Series Analysis\n",
    "Experience with REST APIs and relational databases\n",
    "Excellent written and verbal communication skills\n",
    "Ability to clearly document findings and summarise discussions\n",
    "Drive for excellence, strong attention to detail\n",
    "Excellent organizational and follow-up skills\n",
    "Tech-savvy and passionate about new technologies\n",
    "Bachelor's or Master's Degree required in Computer Science, Mathematics or other related fields.\n",
    "European Unionâ€™s legal working status.\n",
    "Exposure to AWS cloud services: S3, Athena, Aurora, Elasticsearch, Dynamodb, etc...\n",
    "Experience with working with database management systems.\n",
    "\"\"\"\n",
    "\n",
    "# clean text \n",
    "job_description = clean_text(job_description)\n",
    "# extract skill using NESTA skill extractor \n",
    "annotations = detect_skills(job_description, model, nlp, return_dict=True, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations count : 9\n",
      "annotation example description : \n",
      "{'cluster_0': 0.0,\n",
      " 'cluster_1': 0.0,\n",
      " 'cluster_2': 0.0,\n",
      " 'entity': 1139,\n",
      " 'label_cluster_0': 'Transversal skills',\n",
      " 'label_cluster_1': 'General Workplace Skills',\n",
      " 'label_cluster_2': 'General Workplace Skills',\n",
      " 'predicted_q': 0.4968150938837877,\n",
      " 'preferred_label': 'communication',\n",
      " 'surface_form': 'communication',\n",
      " 'surface_form_type': 'label_pref'}\n"
     ]
    }
   ],
   "source": [
    "# annotation  exploration \n",
    "import pprint\n",
    "print(f'annotations count : {len(annotations)}')\n",
    "print('annotation example description : ')\n",
    "pprint.pprint(annotations[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrich a csv file of job postings \n",
    "\n",
    "job_description_col_name = 'job_description'\n",
    "print(' load file ...')\n",
    "path = ''\n",
    "data_input = pd.read_csv(path)\n",
    "\n",
    "print('extract skill ...')\n",
    "# get job description text list \n",
    "job_descriptions = data_input[job_description_col_name].values\n",
    "# create skill extractor util \n",
    "def get_skills(text):\n",
    "    try : \n",
    "\n",
    "        #clean text \n",
    "        text = clean_text(text)\n",
    "        # extract skill using NESTA skill extractor \n",
    "        annotations = detect_skills(text, model, nlp, return_dict=True, debug=False)\n",
    "        # prepare output data [skill_id] (a list of skill ids )\n",
    "        skill_ids = [annotation['entity'] for annotation in annotations]\n",
    "        return skill_ids \n",
    "\n",
    "    except : \n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# apply \n",
    "skills_list = []\n",
    "for job_description in tqdm(job_descriptions):\n",
    "    job_skills = get_skills(job_description)\n",
    "    # stringify \n",
    "    job_skills_str = ';'.join(job_skills)\n",
    "    skills_list.append(job_skills_str)\n",
    "\n",
    "print('merge in input data ...')\n",
    "\n",
    "output_col_name ='esco_skills'\n",
    "data_input[output_col_name] = skills_list\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json \n",
    "import json\n",
    "\n",
    "with open('./data/rekrute_batch_1.json') as json_file:\n",
    "    data_a = json.load(json_file)\n",
    " \n",
    "with open('./data/rekrute_batch_2.json') as json_file:\n",
    "    data_b = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = data_a|data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_elems(sample):\n",
    "\n",
    "    title = sample['title']\n",
    "    country = sample['country']\n",
    "    location = sample['location']\n",
    "    date = sample['date']\n",
    "    sector = sample['sectros']\n",
    "    contract_type = sample['contract_type']\n",
    "    exp = sample['exp_text']\n",
    "    study_level = sample['study_level']\n",
    "    job_description = ' '.join(sample['skills_text']) \n",
    "\n",
    "    return [title,country,location,date,sector,contract_type,exp,study_level,job_description]\n",
    "\n",
    "rows = []\n",
    "for key in full_data : \n",
    "    sample = full_data[key]\n",
    "    row = get_row_elems(sample)\n",
    "    rows.append(sample)\n",
    "\n",
    "# create df \n",
    "cols = ['title','country','location','date','sector','contract_type','exp','study_level','job_description']\n",
    "rekrute_data = pd.DataFrame(rows , columns = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
